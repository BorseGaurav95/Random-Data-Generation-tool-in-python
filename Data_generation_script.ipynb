{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PUXN5X0Qk_pLEiO7g262kIHVQ4fwsDX3",
      "authorship_tag": "ABX9TyP59hI3FdW0fXTAqFSBA/1S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BorseGaurav95/Random-Data-Generation-tool-in-python/blob/main/Data_generation_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Developed by Gaurav Borse"
      ],
      "metadata": {
        "id": "ZoPFJvTPI_rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import random as r\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from google.cloud import bigquery\n",
        "from tqdm import tqdm\n",
        "from google.oauth2 import service_account\n",
        "from shapely.geometry import Point\n",
        "from google.colab import files\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([\n",
        "        \"pip\", \"install\", package\n",
        "    ])\n",
        "\n",
        "install(\"faker\")\n",
        "\n",
        "from faker import Faker\n",
        "fake = Faker()\n",
        "Faker.seed(99)\n",
        "\n",
        "\n",
        "json_file_path=\"\"\n",
        "data = {}\n",
        "count = 0\n",
        "col_name=[]\n",
        "\n",
        "\n",
        "def lat_lng(col_name1):\n",
        "  col_data = \"fake.\"+col_name1+'()'\n",
        "  return float(eval(col_data))\n",
        "\n",
        "def phone_num():\n",
        "  ph_no=[]\n",
        "  ph_no.append(r.randint(6, 9))  \n",
        "  for i in range(1, 10):\n",
        "      ph_no.append(r.randint(0, 9))\n",
        "  res = str(\"\".join(map(str, ph_no)))\n",
        "  return res\n",
        "\n",
        "\n",
        "def zip_data(col_name1):\n",
        "  col_data = \"fake.\"+col_name1+'()'\n",
        "  byte_ch = base64.b64encode(bytes(str(eval(col_data)), 'utf-8')) \n",
        "  return byte_ch.decode('utf-8')\n",
        "\n",
        "\n",
        "def date_time_(col_name1):\n",
        "  col_data = \"fake.\"+col_name1+'()'\n",
        "  str_date=str(eval(col_data))\n",
        "  return str_date\n",
        "\n",
        "def big_num_():\n",
        "   return r.uniform(-5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38,5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38)\n",
        "  \n",
        "def record_data_():\n",
        "  record = {'name': str(fake.name()), 'age': r.randint(1, 99), 'gender':r.choice(['male','female'])}\n",
        "  return record\n",
        "\n",
        "def geography_data():\n",
        "  return str(Point([float(fake.longitude()), float(fake.latitude())]))\n",
        "\n",
        "\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "print(\"Select GCP Service account Json key file = \")\n",
        "# Prompt the user to select multiple files\n",
        "uploaded = files.upload()\n",
        "\n",
        "key, value = list(uploaded.items())[0]\n",
        "json_file_path=\"/content/\"+key;\n",
        "\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "input_table=input(\"Enter BigQuery table name (Project_id.Dataset_name.Table_name) = \")\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "n_record=int(input(\"Enter record count = \"))\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "json_file_path)\n",
        "\n",
        "tb_name=input_table.split(\".\")\n",
        "project_id = tb_name[0]\n",
        "dataset_id = tb_name[1]\n",
        "table_id = tb_name[2]\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT column_name \n",
        "   FROM \"\"\" + project_id + \"\"\".\"\"\" + dataset_id + \"\"\".INFORMATION_SCHEMA.COLUMNS\n",
        "    where table_name = '\"\"\" + table_id + \"\"\"'\n",
        "    \"\"\")\n",
        "\n",
        "results = query_job.result()\n",
        "\n",
        "for row in results:\n",
        "  col_name.append(row.column_name) \n",
        "\n",
        "arr_len=len(col_name)\n",
        "\n",
        "for i in range(n_record):\n",
        "    for j in range(arr_len):  \n",
        "       col_name1 = col_name[j]\n",
        "  \n",
        "       if((col_name1=='latitude') or (col_name1=='longitude')):          \n",
        "          data[col_name1.title()] = lat_lng(col_name1)\n",
        "\n",
        "       elif((col_name1=='phone_number')):    \n",
        "          data[col_name1.title()] = phone_num()\n",
        "\n",
        "       elif((col_name1=='zip')):\n",
        "          data[col_name1.title()] = zip_data(col_name1)\n",
        "\n",
        "       elif((col_name1=='date_time')):\n",
        "          data[col_name1.title()] = date_time_(col_name1)\n",
        "\n",
        "       elif((col_name1=='latlng')):\n",
        "          data[col_name1.title()] = geography_data()\n",
        "\n",
        "       elif((col_name1=='big_num')):\n",
        "          data[col_name1.title()] = big_num_()\n",
        "       \n",
        "       elif((col_name1=='record_data')):\n",
        "          data[col_name1.title()] = record_data_()\n",
        "\n",
        "       else:   \n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = eval(col_data)\n",
        "\n",
        "       rows_to_insert = [data]\n",
        "    \n",
        "       \n",
        "    errors = client.insert_rows_json(input_table, rows_to_insert)  # Make an API request.\n",
        "    count=count+1\n",
        "    \n",
        "    if errors == []:\n",
        "      pass\n",
        "    else:\n",
        "      print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
        "      break\n",
        "\n",
        "for i in tqdm(range(count), desc=\"Loading...\"):\n",
        "      pass\n"
      ],
      "metadata": {
        "id": "1rU79njfUygA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "741b3e2a-b726-40a5-f440-c8d67890e7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n",
            "Select GCP Service account Json key file = \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-16057363-f8a6-4265-bf7b-1fb7d0d03862\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-16057363-f8a6-4265-bf7b-1fb7d0d03862\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wwbq-cartos1-255e5ccf0139.json to wwbq-cartos1-255e5ccf0139 (1).json\n",
            "-------------------------------------------------------------------\n",
            "Enter BigQuery table name (Project_id.Dataset_name.Table_name) = wwbq-cartos1.small_performance.data\n",
            "-------------------------------------------------------------------\n",
            "Enter record count = 10\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading...: 100%|██████████| 10/10 [00:00<00:00, 90394.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "project_id=\"wwbq-cartos1\"\n",
        "cred = service_account.Credentials.from_service_account_file(\"/content/wwbq-cartos1.json\")\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "# Create a BigQuery client\n",
        "\n",
        "\n",
        "# Set the name of the table and the old and new column names\n",
        "table_name = 'wwbq-cartos1.Test_DG.a'\n",
        "old_column_name = 'latitude'\n",
        "new_column_name = 'new_column_name'\n",
        "\n",
        "# Construct the query\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT * FROM ALTER TABLE \"\"\"+table_name+\"\"\" CHANGE COLUMN \"\"\"+old_column_name+\"\"\" \"\"\"+new_column_name+\"\"\" float \"\"\")\n",
        "\n",
        "\n",
        "# Execute the query\n",
        "query_job = client.query(query_job)\n",
        "\n",
        "# Wait for the query to complete\n",
        "query_job.result()\n"
      ],
      "metadata": {
        "id": "oxARSRZxJ1QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Set the project ID and table ID\n",
        "project_id = 'wwbq-cartos1'\n",
        "dataset_id = 'Test_DG'\n",
        "table_id = 'a'\n",
        "\n",
        "# Set the new column name and data type\n",
        "new_column_name = 'new_column_name'\n",
        "new_column_type = 'float'\n",
        "\n",
        "# Create a service client\n",
        "cred = service_account.Credentials.from_service_account_file(\"/content/wwbq-cartos1.json\")\n",
        "service = build('bigquery', 'v2', credentials=cred)\n",
        "\n",
        "# Get the table metadata\n",
        "table = service.tables().get(projectId=project_id, datasetId=dataset_id, tableId=table_id).execute()\n",
        "\n",
        "# Get the list of existing columns\n",
        "columns = table['schema']['fields']\n",
        "\n",
        "# Find the index of the column you want to rename\n",
        "column_index = -1\n",
        "for i, column in enumerate(columns):\n",
        "  if column['name'] == 'latit':\n",
        "    column_index = i\n",
        "    \n",
        "    break\n",
        "\n",
        "\n",
        "# If the column was found, update its name and data type\n",
        "if column_index >= 0:\n",
        "  columns[column_index]['name'] = new_column_name\n",
        "  print(\"yes\")\n",
        "  columns[column_index]['type'] = new_column_type\n",
        "\n",
        "# Update the table schema\n",
        "table['schema']['fields'] = columns\n",
        "service.tables().patch(projectId=project_id, datasetId=dataset_id, tableId=table_id, body=table).execute()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4hjwf0xJ1_-",
        "outputId": "c38025c3-1f8b-4332-cf04-ff1288d1c84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kind': 'bigquery#table',\n",
              " 'etag': '5F752ofsd5zRZOxIpg1Tuw==',\n",
              " 'id': 'wwbq-cartos1:Test_DG.a',\n",
              " 'selfLink': 'https://bigquery.googleapis.com/bigquery/v2/projects/wwbq-cartos1/datasets/Test_DG/tables/a',\n",
              " 'tableReference': {'projectId': 'wwbq-cartos1',\n",
              "  'datasetId': 'Test_DG',\n",
              "  'tableId': 'a'},\n",
              " 'schema': {'fields': [{'name': 'latitude',\n",
              "    'type': 'FLOAT',\n",
              "    'mode': 'NULLABLE'}]},\n",
              " 'numBytes': '0',\n",
              " 'numLongTermBytes': '0',\n",
              " 'numRows': '0',\n",
              " 'creationTime': '1672507471746',\n",
              " 'lastModifiedTime': '1672507471798',\n",
              " 'type': 'TABLE',\n",
              " 'location': 'US',\n",
              " 'numTimeTravelPhysicalBytes': '1248',\n",
              " 'numTotalLogicalBytes': '0',\n",
              " 'numActiveLogicalBytes': '0',\n",
              " 'numLongTermLogicalBytes': '0',\n",
              " 'numTotalPhysicalBytes': '1248',\n",
              " 'numActivePhysicalBytes': '1248',\n",
              " 'numLongTermPhysicalBytes': '0'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import random as r\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from google.cloud import bigquery\n",
        "from tqdm import tqdm\n",
        "from google.oauth2 import service_account\n",
        "from shapely.geometry import Point\n",
        "from google.colab import files\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([\n",
        "        \"pip\", \"install\", package\n",
        "    ])\n",
        "\n",
        "install(\"faker\")\n",
        "\n",
        "from faker import Faker\n",
        "\n",
        "json_file_path=\"\"\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "print(\"Select GCP Service account Json key file = \")\n",
        "# Prompt the user to select multiple files\n",
        "uploaded = files.upload()\n",
        "\n",
        "key, value = list(uploaded.items())[0]\n",
        "json_file_path=\"/content/\"+key;\n",
        "\n",
        " \n",
        "print(\"-------------------------------------------------------------------\")\n",
        "input_table=input(\"Enter BigQuery table name (Project_id.Dataset_name.Table_name) = \")\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "n_record=int(input(\"Enter record count = \"))\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "json_file_path)\n",
        "\n",
        "tb_name=input_table.split(\".\")\n",
        "project_id = tb_name[0]\n",
        "dataset_id = tb_name[1]\n",
        "table_id = tb_name[2]\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT column_name \n",
        "   FROM \"\"\" + project_id + \"\"\".\"\"\" + dataset_id + \"\"\".INFORMATION_SCHEMA.COLUMNS\n",
        "    where table_name = '\"\"\" + table_id + \"\"\"'\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "results = query_job.result()\n",
        "\n",
        "col_name=[]\n",
        "\n",
        "for row in results:\n",
        "  col_name.append(row.column_name) \n",
        "\n",
        "arr_len=len(col_name)\n",
        "\n",
        "data = {}\n",
        "count = 0\n",
        "\n",
        "fake = Faker()\n",
        "Faker.seed(99)\n",
        "\n",
        "for i in range(n_record):\n",
        "    for j in range(arr_len):  \n",
        "       col_name1 = col_name[j]\n",
        "  \n",
        "       if((col_name1=='latitude') or (col_name1=='longitude')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = float(eval(col_data))\n",
        "       elif((col_name1=='phone_number')):\n",
        "          # col_data = \"fake.\"+col_name1+'()'\n",
        "          # data[col_name1.title()] = eval(col_data)\n",
        "          ph_no=[]\n",
        "          ph_no.append(r.randint(6, 9))  \n",
        "          for i in range(1, 10):\n",
        "              ph_no.append(r.randint(0, 9))\n",
        "          res = str(\"\".join(map(str, ph_no)))\n",
        "          data[col_name1.title()] = res\n",
        "       elif((col_name1=='zip')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          byte_ch = base64.b64encode(bytes(str(eval(col_data)), 'utf-8'))\n",
        "          data[col_name1.title()] = byte_ch.decode('utf-8')\n",
        "       elif((col_name1=='date_time')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          str_date=str(eval(col_data))\n",
        "          data[col_name1.title()] = str_date\n",
        "          #data[col_name1.title()] = parser.parse(str_date)\n",
        "          #print(data[col_name1.title()])\n",
        "          #data[col_name1.title()] =  datetime.strptime(str_date, '%')\n",
        "       elif((col_name1=='pydecimal')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          big_num=str(eval(col_data))\n",
        "          data[col_name1.title()] = big_num\n",
        "       elif((col_name1=='latlng')):\n",
        "          data[col_name1.title()] = str(Point(\n",
        "          [float(fake.longitude()), float(fake.latitude())]))\n",
        "       elif((col_name1=='big_num')):\n",
        "          data[col_name1.title()] = r.uniform(-5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38,5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38)\n",
        "       elif((col_name1=='record_data')):\n",
        "          data[col_name1.title()] = record = {'name': str(fake.name()), 'age': r.randint(1, 99), 'gender':r.choice(['male','female'])}\n",
        "\n",
        "       else:   \n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = eval(col_data)\n",
        "       rows_to_insert = [data]\n",
        "    # print(rows_to_insert)\n",
        "       \n",
        "    errors = client.insert_rows_json(input_table, rows_to_insert)  # Make an API request.\n",
        "    count=count+1\n",
        "    if errors == []:\n",
        "      pass\n",
        "    else:\n",
        "      print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
        "      break\n",
        "for i in tqdm(range(count), desc=\"Loading...\"):\n",
        "      pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "e7d133a4-6bda-4eaa-b65b-31d39524eefe",
        "id": "Yz-W6nSiJ2gA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n",
            "Select GCP Service account Json key file = \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f1a1290-c297-4bc1-b341-01a5b020a968\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2f1a1290-c297-4bc1-b341-01a5b020a968\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wwbq-cartos1.json to wwbq-cartos1.json\n",
            "-------------------------------------------------------------------\n",
            "Enter BigQuery table name (Project_id.Dataset_name.Table_name) = wwbq-cartos1.Test_DG.a\n",
            "-------------------------------------------------------------------\n",
            "Enter record count = 1\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading...: 100%|██████████| 1/1 [00:00<00:00, 6932.73it/s]\n"
          ]
        }
      ]
    }
  ]
}